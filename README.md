
# TruLens-eval with Google Gemini Examples

This repository provides practical examples of using `trulens-eval` to evaluate the quality and relevance of AI-generated content, with a specific focus on using Google's Gemini models as the evaluation provider.

## ğŸŒŸ Overview

These examples demonstrate how to integrate `trulens-eval` into your AI applications to gain deeper insights into their performance. You will learn how to:

-   **Trace & Evaluate a LangGraph Agent**: Automatically record a multi-step agent's execution and evaluate the relevance of its retrieved context.
-   **Use Custom Feedback Functions**: Assess the quality of a generated plan against specific criteria using a standalone feedback function.

## ğŸš€ Examples Included

1.  **`context_relevance.py`**:
    -   Builds a simple agent using `LangGraph` that searches for information with the `Tavily` tool.
    -   Uses `TruGraph` to trace the application's execution.
    -   Evaluates the relevance of the search results (context) to the user's query using the `Context Relevance` feedback function from `trulens-eval`.
    -   Launches the TruLens dashboard to visualize the trace and evaluation results.

2.  **`plan_quality.py`**:
    -   Directly evaluates two predefined text plans (one mediocre, one excellent) without running a full AI application.
    -   Demonstrates the usage of the `plan_quality_with_cot_reasons` feedback function to get a nuanced quality score and detailed reasoning from Gemini.

## ğŸ› ï¸ Setup and Installation

Follow these steps to get the examples running on your local machine.

**1. Clone the Repository**

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

**2. Create a Virtual Environment (Recommended)**

```bash
python -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
```

**3. Install Dependencies**

All required packages are listed in `requirements.txt`.

```bash
pip install -r requirements.txt
```

**4. Configure Environment Variables**

You need to provide API keys for Google and Tavily.

-   Copy the example file `.env.example` to a new file named `.env`.
    ```bash
    cp .env.example .env
    ```
-   Open the `.env` file and add your personal API keys.
    -   `GOOGLE_API_KEY`: Required for `trulens-eval`'s feedback provider. Get it from [Google AI Studio](https://aistudio.google.com/app/apikey).
    -   `TAVILY_API_KEY`: Required for the search tool in `context_relevance.py`. Get it from [Tavily AI](https://app.tavily.com/).

## â–¶ï¸ How to Run

**Example 1: Evaluate Context Relevance in an Agent**

This script will run the LangGraph agent, record the trace, perform the evaluation, print the results to the console, and start the TruLens dashboard.

```bash
python context_relevance.py
```

-   **Expected Output**: The console will show the agent's output and a summary of the feedback results.
-   **Dashboard**: A local dashboard will be available at `http://localhost:8501` for detailed inspection of traces and evaluations.

**Example 2: Evaluate Plan Quality**

This script will directly evaluate the two hardcoded plans and print their scores and the reasoning behind them.

```bash
python plan_quality.py
```

-   **Expected Output**: You will see a detailed breakdown in the console for both the "mediocre" and "excellent" plans, including a quality score (0-100) and the evaluation logic from Gemini.

---
---

# TruLens-eval ç»“åˆ Google Gemini ç¤ºä¾‹

[English](./README.md) | ç®€ä½“ä¸­æ–‡

æœ¬ä»£ç åº“æä¾›äº†ä¸€ç³»åˆ—å®ç”¨ç¤ºä¾‹ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `trulens-eval` è¯„ä¼° AI ç”Ÿæˆå†…å®¹çš„è´¨é‡ä¸ç›¸å…³æ€§ï¼Œå¹¶é‡ç‚¹å±•ç¤ºäº†å¦‚ä½•é›†æˆ Google Gemini æ¨¡å‹ä½œä¸ºè¯„ä¼°æœåŠ¡æä¾›æ–¹ï¼ˆProviderï¼‰ã€‚

## ğŸŒŸ æ¦‚è§ˆ

è¿™äº›ç¤ºä¾‹å°†å¸®åŠ©æ‚¨ç†è§£å¦‚ä½•å°† `trulens-eval` é›†æˆåˆ°æ‚¨çš„ AI åº”ç”¨ä¸­ï¼Œä»è€Œæ·±å…¥æ´å¯Ÿå…¶æ€§èƒ½ã€‚æ‚¨å°†å­¦ä¹ åˆ°ï¼š

-   **è¿½è¸ªä¸è¯„ä¼° LangGraph Agent**: è‡ªåŠ¨è®°å½•ä¸€ä¸ªå¤šæ­¥ Agent çš„å®Œæ•´æ‰§è¡Œè¿‡ç¨‹ï¼Œå¹¶è¯„ä¼°å…¶æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼ˆContextï¼‰çš„ç›¸å…³æ€§ã€‚
-   **ä½¿ç”¨è‡ªå®šä¹‰ Feedback åŠŸèƒ½**: ä½¿ç”¨ç‹¬ç«‹çš„ Feedback å‡½æ•°ï¼Œæ ¹æ®ç‰¹å®šæ ‡å‡†è¯„ä¼°ä¸€ä¸ªâ€œè®¡åˆ’â€æ–‡æœ¬çš„è´¨é‡ã€‚

## ğŸš€ ç¤ºä¾‹è¯´æ˜

1.  **`context_relevance.py`**:
    -   ä½¿ç”¨ `LangGraph` æ„å»ºä¸€ä¸ªç®€å•çš„ Agentï¼Œè¯¥ Agent é€šè¿‡ `Tavily` å·¥å…·è¿›è¡Œä¿¡æ¯æ£€ç´¢ã€‚
    -   ä½¿ç”¨ `TruGraph` åŒ…è£…å™¨æ¥è¿½è¸ªåº”ç”¨çš„æ‰§è¡Œæµç¨‹ã€‚
    -   åˆ©ç”¨ `trulens-eval` çš„ `Context Relevance`ï¼ˆä¸Šä¸‹æ–‡ç›¸å…³æ€§ï¼‰Feedback å‡½æ•°ï¼Œè¯„ä¼°æœç´¢ç»“æœï¼ˆä¸Šä¸‹æ–‡ï¼‰ä¸ç”¨æˆ·æŸ¥è¯¢çš„åŒ¹é…ç¨‹åº¦ã€‚
    -   è¿è¡Œç»“æŸåï¼Œå¯åŠ¨ TruLens Dashboard ä»¥ä¾¿å¯¹è¿½è¸ªå’Œè¯„ä¼°ç»“æœè¿›è¡Œå¯è§†åŒ–åˆ†æã€‚

2.  **`plan_quality.py`**:
    -   ä¸è¿è¡Œå®Œæ•´çš„ AI åº”ç”¨ï¼Œè€Œæ˜¯ç›´æ¥è¯„ä¼°ä¸¤ä¸ªé¢„å®šä¹‰çš„è®¡åˆ’æ–‡æœ¬ï¼ˆä¸€ä¸ªä¸­ç­‰è´¨é‡ï¼Œä¸€ä¸ªé«˜è´¨é‡ï¼‰ã€‚
    -   æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ `plan_quality_with_cot_reasons` Feedback å‡½æ•°ï¼Œä» Gemini è·å¾—ç²¾ç¡®çš„è´¨é‡åˆ†æ•°å’Œè¯¦ç»†çš„è¯„ä¼°ç†ç”±ã€‚

## ğŸ› ï¸ ç¯å¢ƒè®¾ç½®ä¸å®‰è£…

è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤åœ¨æ‚¨çš„æœ¬åœ°ç¯å¢ƒä¸­è¿è¡Œè¿™äº›ç¤ºä¾‹ã€‚

**1. å…‹éš†ä»£ç åº“**

```bash
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name
```

**2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)**

```bash
python -m venv venv
source venv/bin/activate  # Windows ç³»ç»Ÿè¯·ä½¿ç”¨ `venv\Scripts\activate`
```

**3. å®‰è£…ä¾èµ–**

æ‰€æœ‰å¿…éœ€çš„ Python åŒ…éƒ½å·²åœ¨ `requirements.txt` æ–‡ä»¶ä¸­åˆ—å‡ºã€‚

```bash
pip install -r requirements.txt
```

**4. é…ç½®ç¯å¢ƒå˜é‡**

æ‚¨éœ€è¦æä¾› Google å’Œ Tavily çš„ API å¯†é’¥ã€‚

-   é¦–å…ˆï¼Œå°†ç¯å¢ƒå˜é‡ç¤ºä¾‹æ–‡ä»¶ `.env.example` å¤åˆ¶ä¸ºæ–°æ–‡ä»¶ `.env`ã€‚
    ```bash
    cp .env.example .env
    ```
-   ç„¶åï¼Œç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„ä¸ªäºº API å¯†é’¥ã€‚
    -   `GOOGLE_API_KEY`: `trulens-eval` çš„ Feedback Provider éœ€è¦æ­¤å¯†é’¥ã€‚æ‚¨å¯ä»¥ä» [Google AI Studio](https://aistudio.google.com/app/apikey) è·å–ã€‚
    -   `TAVILY_API_KEY`: `context_relevance.py` ç¤ºä¾‹ä¸­çš„æœç´¢å·¥å…·éœ€è¦æ­¤å¯†é’¥ã€‚æ‚¨å¯ä»¥ä» [Tavily AI](https://app.tavily.com/) è·å–ã€‚

## â–¶ï¸ å¦‚ä½•è¿è¡Œ

**ç¤ºä¾‹ 1: è¯„ä¼° Agent çš„ä¸Šä¸‹æ–‡ç›¸å…³æ€§**

æ­¤è„šæœ¬å°†è¿è¡Œ LangGraph Agentï¼Œè®°å½•å…¶è¿½è¸ªæ•°æ®ï¼Œæ‰§è¡Œè¯„ä¼°ï¼Œå°†ç»“æœæ‰“å°åˆ°æ§åˆ¶å°ï¼Œå¹¶å¯åŠ¨ TruLens Dashboardã€‚

```bash
python context_relevance.py
```

-   **é¢„æœŸè¾“å‡º**: æ§åˆ¶å°å°†æ˜¾ç¤º Agent çš„æœ€ç»ˆè¾“å‡ºä»¥åŠ Feedback è¯„ä¼°ç»“æœçš„æ‘˜è¦ã€‚
-   **Dashboard**: è„šæœ¬ä¼šè‡ªåŠ¨å¯åŠ¨ä¸€ä¸ªæœ¬åœ°ç½‘ç«™ï¼Œé€šå¸¸åœ¨ `http://localhost:8501`ï¼Œæ‚¨å¯ä»¥åœ¨å…¶ä¸­æŸ¥çœ‹è¯¦ç»†çš„è°ƒç”¨é“¾å’Œè¯„ä¼°æ•°æ®ã€‚

**ç¤ºä¾‹ 2: è¯„ä¼°è®¡åˆ’è´¨é‡**

æ­¤è„šæœ¬å°†ç›´æ¥è¯„ä¼°ä»£ç ä¸­é¢„è®¾çš„ä¸¤ä¸ªè®¡åˆ’ï¼Œå¹¶æ‰“å°å‡ºå®ƒä»¬å„è‡ªçš„å¾—åˆ†ä¸è¯„ä¼°ç†ç”±ã€‚

```bash
python plan_quality.py
```

-   **é¢„æœŸè¾“å‡º**: æ‚¨å°†åœ¨æ§åˆ¶å°ä¸­çœ‹åˆ°å¯¹â€œæœ‰å¾…æ”¹è¿›çš„è®¡åˆ’â€å’Œâ€œä¼˜ç§€çš„è®¡åˆ’â€çš„è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬ä¸€ä¸ª 0-100 åˆ†åˆ¶çš„è´¨é‡è¯„åˆ†ä»¥åŠæ¥è‡ª Gemini çš„è¯„ä¼°é€»è¾‘ã€‚